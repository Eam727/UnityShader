参考自：Unity Shader入门精要
参考链接：[Rocky Lai 的技术博客](http://blog.shuiguzi.com/2015/04/28/Shader_2/)


**渲染管线(Rendering Pipeline)**

说的俗一点就是可以理解为流水线。渲染管线我们可暂时理解为 **从得到模型数据到绘制出图像** 这一过程的称呼。

**工作任务**：由一个三维场景出发、生成（或者说渲染）一张二维图像。

换句话说，计算机需要从一系列的顶点数据、纹理等信息出发，把这些信息最终转换成一张人眼可以看到的图像。
这个工作通常是由CPU和GPU共同完成。

渲染流程分为3个阶段：**应用阶段、几何阶段、光栅化阶段**。

注意：这里仅仅是概念性阶段，每个阶段本身通常也是一个流水线系统，即包含了子流水线阶段。

![](https://i.imgur.com/hGR5fLE.png)

为了更好理解和记忆这节内容，先来学下面几个词。

- **Vertex Shader顶点着色器**： 对顶点数据编程的一段程序。一般称其为 VS。
- **Fragment Shader片元着色器**： 对像素数据编程的一段程序。这里 fragment 可以理解为带有信息（颜色，坐标等）的像素 (Pixel), 一般也简称其为 FS 或者 PS 。 
- **FrameBuffer**： 缓存帧数据的存储区，它一般包含的是要显示到显示设备上的位图数据（也就是图片数据）。
- **Fixed Function**： 由于一些硬件支持等历史原因，早期的图形 API 只支持对 GPU 做配置，这部分只可配置的功能就是 fixed fucntion。这里注意下，fixed function 的功能只能配置，不像 Vertex Shader　和 fragment Shader 可以编程（写自己的算法）。

![](https://i.imgur.com/X3H4vUt.jpg)

上面是可编程的渲染管线模型的示意。下面多说几点：

- 输入阶段。Unity 使用 Mesh Renderer 等组件读取模型顶点数据，然后调用图形 API，将数据传递给 GPU。
- 现实中同时会进行多条渲染管线，他们是并行的。 这点概念比较重要，以后还会提到它。我们记住 GPU 并行能力很强。
- 最后输出的 FrameBuffer (可以理解为渲染出来的图片) 有几率被抛弃掉，也就是说不显示在显示设备上。这个以后单独说明原因。好比残酷的现实世界，努力了（整个渲染过程）也不一定会成功（被显示出来）。

**小结**
渲染管道是从得模型数据到图像生成过程的一种描述。Vertex Shader 能对顶点数据写处理算法，而 Fragment Shader 能对像素数据写处理算法。

----------
#渲染流水线三个阶段：#

###**1.应用阶段**(CPU)###
开发者具有这个阶段的绝对控制权。

**任务：**

 -  **准备好场景数据**，如：摄像机位置、视锥体、场景中包含哪些模型、使用了哪些光源等等。
 -   （为了提高渲染性能**）做一个粗粒度剔除工作**，以把那些不可见的物体剔除出去，这样就不需要再移交几何阶段处理。
 -   **设置好每个模型的渲染状态**，包括但不限于：使用的材质（漫反射颜色、高光反射颜色）、使用的纹理、使用的Shader等。

这一阶段最重要的输出是渲染所需的几何信息，即**渲染图元**。
通俗来说，渲染图元可以是点、线、三角面等。这些渲染图元将会被传递给下一个阶段--几何阶段。

###**2.几何阶段**(GPU)###
处理所有和我们要绘制的几何相关的事情。如：决定需要绘制的图元是什么，怎么绘制他们，在哪里绘制。


几何阶段负责：**和每个渲染图元打交道，进行逐顶点、逐多边形的操作**。这个阶段可以进一步分成更小的流水线阶段。

**重要任务**：
把顶点坐标变换到屏幕空间中，再交给光栅器进行处理。

通过对输入的渲染图元进行多步处理后，这一阶段将会输出屏幕空间的二维顶点坐标、每个顶点对应的深度值、着色等相关信息，并传递给下一个阶段。

###**3.光栅化阶段**（GPU）###
使用上个阶段传递的数据来产生屏幕的像素，并渲染出最终的图像。

**主要任务**：
决定每个渲染图元中的哪些像素应该被绘制在屏幕上。

它需要对上一个阶段得到的逐顶点数据（例如纹理坐标、顶点颜色等）进行插值，然后再进行逐像素处理。
